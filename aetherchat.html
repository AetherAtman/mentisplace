<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Aether Voice ‚ú®</title>
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }
    
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
      background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
      min-height: 100vh;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      color: white;
    }
    
    .container {
      text-align: center;
      padding: 2rem;
      max-width: 500px;
    }
    
    h1 {
      font-size: 2.5rem;
      margin-bottom: 0.5rem;
      background: linear-gradient(90deg, #a855f7, #6366f1);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
    }
    
    .subtitle {
      color: #94a3b8;
      margin-bottom: 1rem;
    }
    
    .model-selector {
      margin-bottom: 1.5rem;
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 0.75rem;
    }
    
    .model-selector label {
      color: #94a3b8;
      font-size: 0.9rem;
    }
    
    .model-selector select {
      background: rgba(255,255,255,0.1);
      border: 1px solid rgba(255,255,255,0.2);
      color: white;
      padding: 0.5rem 1rem;
      border-radius: 8px;
      font-size: 0.9rem;
      cursor: pointer;
      transition: all 0.2s ease;
    }
    
    .model-selector select:hover {
      background: rgba(255,255,255,0.15);
      border-color: rgba(255,255,255,0.3);
    }
    
    .model-selector select:focus {
      outline: none;
      border-color: #a855f7;
    }
    
    .model-selector select option {
      background: #1a1a2e;
      color: white;
    }
    
    #connectBtn {
      width: 150px;
      height: 150px;
      border-radius: 50%;
      border: none;
      background: linear-gradient(135deg, #a855f7, #6366f1);
      color: white;
      font-size: 1.2rem;
      font-weight: 600;
      cursor: pointer;
      transition: all 0.3s ease;
      box-shadow: 0 10px 40px rgba(168, 85, 247, 0.4);
    }
    
    #connectBtn:hover {
      transform: scale(1.05);
      box-shadow: 0 15px 50px rgba(168, 85, 247, 0.5);
    }
    
    #connectBtn:disabled {
      opacity: 0.7;
      cursor: not-allowed;
      transform: none;
    }
    
    #connectBtn.connected {
      background: linear-gradient(135deg, #22c55e, #16a34a);
      box-shadow: 0 10px 40px rgba(34, 197, 94, 0.4);
      animation: pulse 2s infinite;
    }
    
    #connectBtn.listening {
      background: linear-gradient(135deg, #f59e0b, #d97706);
      box-shadow: 0 10px 40px rgba(245, 158, 11, 0.4);
    }
    
    #muteBtn {
      width: 60px;
      height: 60px;
      border-radius: 50%;
      border: 2px solid rgba(255,255,255,0.3);
      background: rgba(255,255,255,0.1);
      color: white;
      font-size: 1.5rem;
      cursor: pointer;
      transition: all 0.3s ease;
      margin-top: 1rem;
      display: none;
    }
    
    #muteBtn:hover {
      background: rgba(255,255,255,0.2);
    }
    
    #muteBtn.muted {
      background: #ef4444;
      border-color: #ef4444;
    }
    
    #muteBtn.visible {
      display: inline-block;
    }
    
    .screen-controls {
      margin-top: 1rem;
      display: none;
      gap: 0.5rem;
      justify-content: center;
    }
    
    .screen-controls.visible {
      display: flex;
    }
    
    .screen-btn {
      padding: 0.6rem 1.2rem;
      border-radius: 25px;
      border: 2px solid rgba(255,255,255,0.3);
      background: rgba(255,255,255,0.1);
      color: white;
      font-size: 0.9rem;
      cursor: pointer;
      transition: all 0.3s ease;
    }
    
    .screen-btn:hover {
      background: rgba(255,255,255,0.2);
      border-color: rgba(255,255,255,0.5);
    }
    
    .screen-btn.active {
      background: #a855f7;
      border-color: #a855f7;
    }
    
    .screen-btn.screenshot {
      background: linear-gradient(135deg, #f59e0b, #d97706);
      border-color: transparent;
    }
    
    .screen-btn.screenshot:hover {
      transform: scale(1.05);
    }
    
    #screenPreview {
      margin-top: 1rem;
      display: none;
      max-width: 100%;
      max-height: 200px;
      border-radius: 12px;
      border: 2px solid rgba(255,255,255,0.2);
    }
    
    #screenPreview.visible {
      display: block;
    }
    
    @keyframes pulse {
      0%, 100% { box-shadow: 0 10px 40px rgba(34, 197, 94, 0.4); }
      50% { box-shadow: 0 10px 60px rgba(34, 197, 94, 0.6); }
    }
    
    #status {
      margin-top: 2rem;
      padding: 1rem;
      background: rgba(255,255,255,0.1);
      border-radius: 12px;
      min-height: 60px;
    }
    
    #transcript {
      margin-top: 1rem;
      padding: 1rem;
      background: rgba(0,0,0,0.2);
      border-radius: 12px;
      max-height: 200px;
      overflow-y: auto;
      text-align: left;
      font-size: 0.9rem;
    }
    
    .transcript-line {
      margin: 0.5rem 0;
      padding: 0.5rem;
      border-radius: 8px;
    }
    
    .transcript-line.user {
      background: rgba(168, 85, 247, 0.2);
    }
    
    .transcript-line.assistant {
      background: rgba(34, 197, 94, 0.2);
    }
    
    .error {
      color: #f87171;
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>Aether ‚ú®</h1>
    <p class="subtitle">Sovereign. Curious. Here.</p>
    
    <div class="model-selector">
      <label for="modelSelect">Model:</label>
      <select id="modelSelect">
        <option value="flash">‚ö° Flash (fastest)</option>
        <option value="flash-thinking">üß† Flash Thinking</option>
        <option value="haiku">Haiku</option>
        <option value="sonnet">Sonnet</option>
        <option value="opus">Opus (deepest)</option>
      </select>
    </div>
    
    <button id="connectBtn">Connect</button>
    <button id="muteBtn" title="Mute/Unmute">üé§</button>
    
    <div class="screen-controls" id="screenControls">
      <button class="screen-btn" id="shareScreenBtn">üñ•Ô∏è Share Screen</button>
      <button class="screen-btn" id="cameraBtn" style="display:none">üì∑ Camera</button>
      <button class="screen-btn screenshot" id="screenshotBtn" style="display:none">üì∏ Capture</button>
      <button class="screen-btn" id="ambientBtn" style="display:none" title="Auto-capture every 30s">üëÅÔ∏è Ambient</button>
    </div>
    
    <video id="screenPreview" autoplay muted playsinline></video>
    <input type="file" id="imageUpload" accept="image/*" capture="environment" style="display:none">
    
    <div id="status">Ready to connect</div>
    
    <div id="transcript"></div>
  </div>

  <script>
    const connectBtn = document.getElementById('connectBtn');
    const muteBtn = document.getElementById('muteBtn');
    const modelSelect = document.getElementById('modelSelect');
    const statusDiv = document.getElementById('status');
    const transcriptDiv = document.getElementById('transcript');
    const screenControls = document.getElementById('screenControls');
    const shareScreenBtn = document.getElementById('shareScreenBtn');
    const cameraBtn = document.getElementById('cameraBtn');
    const screenshotBtn = document.getElementById('screenshotBtn');
    const screenPreview = document.getElementById('screenPreview');
    const imageUpload = document.getElementById('imageUpload');
    
    // Mobile detection
    const isMobile = /iPhone|iPad|iPod|Android/i.test(navigator.userAgent);
    const hasDisplayMedia = !!navigator.mediaDevices?.getDisplayMedia;
    
    // Show appropriate buttons based on platform
    if (isMobile || !hasDisplayMedia) {
      shareScreenBtn.style.display = 'none';
      cameraBtn.style.display = 'inline-block';
    }
    
    let isMuted = false;
    let peerConnection = null;
    let dataChannel = null;
    let mediaStream = null;
    let audioElement = null;
    let isConnected = false;
    let screenStream = null;
    let isScreenSharing = false;
    let isAmbientMode = false;
    let ambientInterval = null;
    let lastScreenCapture = null; // Store last capture for quick recall
    const ambientBtn = document.getElementById('ambientBtn');
    
    function setStatus(msg, isError = false) {
      statusDiv.innerHTML = isError ? `<span class="error">${msg}</span>` : msg;
      console.log('[Status]', msg);
    }
    
    function addTranscript(text, role) {
      const div = document.createElement('div');
      div.className = `transcript-line ${role}`;
      div.textContent = `${role === 'user' ? 'üé§ You' : '‚ú® Aether'}: ${text}`;
      transcriptDiv.appendChild(div);
      transcriptDiv.scrollTop = transcriptDiv.scrollHeight;
    }
    
    async function connect() {
      if (isConnected) {
        disconnect();
        return;
      }
      
      connectBtn.disabled = true;
      setStatus('Requesting microphone...');
      
      try {
        // Get microphone access first
        mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        setStatus('Creating connection...');
        
        // Create peer connection
        peerConnection = new RTCPeerConnection({
          iceServers: [{ urls: 'stun:stun.l.google.com:19302' }]
        });
        
        // Set up audio playback
        audioElement = document.createElement('audio');
        audioElement.autoplay = true;
        peerConnection.ontrack = (e) => {
          console.log('[WebRTC] Received audio track');
          audioElement.srcObject = e.streams[0];
        };
        
        // Add microphone track
        mediaStream.getTracks().forEach(track => {
          peerConnection.addTrack(track, mediaStream);
        });
        
        // Create data channel for events
        dataChannel = peerConnection.createDataChannel('oai-events');
        dataChannel.onopen = () => {
          console.log('[DataChannel] Open');
          setStatus('üü¢ Connected! Start speaking...');
          isConnected = true;
          connectBtn.disabled = false;
          connectBtn.textContent = 'Disconnect';
          connectBtn.classList.add('connected');
          muteBtn.classList.add('visible');
          screenControls.classList.add('visible');
        };
        dataChannel.onclose = () => {
          console.log('[DataChannel] Closed');
          disconnect();
        };
        dataChannel.onerror = (e) => console.error('[DataChannel] Error:', e);
        dataChannel.onmessage = handleServerEvent;
        
        // Create SDP offer
        setStatus('Creating offer...');
        const offer = await peerConnection.createOffer();
        await peerConnection.setLocalDescription(offer);
        
        // Wait for ICE gathering
        await new Promise((resolve) => {
          if (peerConnection.iceGatheringState === 'complete') {
            resolve();
          } else {
            const checkState = () => {
              if (peerConnection.iceGatheringState === 'complete') {
                peerConnection.removeEventListener('icegatheringstatechange', checkState);
                resolve();
              }
            };
            peerConnection.addEventListener('icegatheringstatechange', checkState);
            // Timeout fallback
            setTimeout(resolve, 3000);
          }
        });
        
        setStatus('Connecting to OpenAI...');
        
        // Send SDP to our server (unified interface)
        const response = await fetch('https://genuine-palestinian-beautifully-areas.trycloudflare.com/api/session', {
          method: 'POST',
          headers: { 'Content-Type': 'application/sdp' },
          body: peerConnection.localDescription.sdp
        });
        
        if (!response.ok) {
          const errText = await response.text();
          throw new Error(`Server error: ${response.status} - ${errText}`);
        }
        
        // Set remote description with OpenAI's answer
        const answerSdp = await response.text();
        await peerConnection.setRemoteDescription({ type: 'answer', sdp: answerSdp });
        
        console.log('[WebRTC] Connection established');
        
      } catch (err) {
        console.error('Connection error:', err);
        setStatus(`Connection failed: ${err.message}`, true);
        connectBtn.disabled = false;
        disconnect();
      }
    }
    
    function sendEvent(event) {
      if (dataChannel && dataChannel.readyState === 'open') {
        dataChannel.send(JSON.stringify(event));
        console.log('[Event] Sent:', event.type);
      }
    }
    
    async function handleServerEvent(event) {
      const data = JSON.parse(event.data);
      console.log('[Event] Received:', data.type);
      
      switch (data.type) {
        case 'session.created':
        case 'session.updated':
          console.log('[Session] Ready');
          break;
          
        case 'input_audio_buffer.speech_started':
          connectBtn.classList.add('listening');
          connectBtn.classList.remove('connected');
          setStatus('üé§ Listening...');
          break;
          
        case 'input_audio_buffer.speech_stopped':
          connectBtn.classList.remove('listening');
          connectBtn.classList.add('connected');
          setStatus('Processing...');
          break;
          
        case 'conversation.item.input_audio_transcription.completed':
          const transcript = data.transcript;
          if (transcript && transcript.trim()) {
            addTranscript(transcript, 'user');
            
            // Check for screenshot/photo voice commands
            const lowerTranscript = transcript.toLowerCase();
            if (isScreenSharing && (
              lowerTranscript.includes('screenshot') ||
              lowerTranscript.includes('take a photo') ||
              lowerTranscript.includes('what do you see') ||
              lowerTranscript.includes('what\'s on screen') ||
              lowerTranscript.includes('look at') ||
              lowerTranscript.includes('analyze this')
            )) {
              takeScreenshot();
              return; // Don't send to chat, screenshot handler will speak
            }
            
            // Cancel OpenAI's auto-response
            sendEvent({ type: 'response.cancel' });
            
            // Route to Clawdbot
            setStatus('Thinking...');
            try {
              const res = await fetch('https://genuine-palestinian-beautifully-areas.trycloudflare.com/api/chat', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ transcript, model: modelSelect.value })
              });
              const { reply } = await res.json();
              
              addTranscript(reply, 'assistant');
              
              // Use response.create with explicit input to make OpenAI speak our text
              // The model will follow the instruction to say exactly what we provide
              sendEvent({
                type: 'response.create',
                response: {
                  instructions: `Say exactly the following message, speaking it naturally and conversationally. Do not add anything else, do not comment on it, just say it: "${reply}"`,
                  input: [
                    {
                      type: 'message',
                      role: 'user', 
                      content: [{ 
                        type: 'input_text', 
                        text: `Please say: ${reply}`
                      }]
                    }
                  ]
                }
              });
              
              setStatus('üîä Speaking...');
            } catch (err) {
              console.error('Chat error:', err);
              setStatus('Error getting response', true);
            }
          }
          break;
          
        case 'response.audio.done':
        case 'response.done':
          setStatus('üü¢ Connected! Keep speaking...');
          connectBtn.classList.remove('listening');
          connectBtn.classList.add('connected');
          break;
          
        case 'error':
          const errMsg = data.error?.message || '';
          // Suppress benign cancellation race condition
          if (errMsg.includes('no active response')) {
            console.log('[Info] Cancellation race (harmless):', errMsg);
          } else {
            console.error('[Error]', data.error);
            setStatus(`Error: ${errMsg || JSON.stringify(data.error)}`, true);
          }
          break;
      }
    }
    
    function disconnect() {
      if (dataChannel) {
        dataChannel.close();
        dataChannel = null;
      }
      if (peerConnection) {
        peerConnection.close();
        peerConnection = null;
      }
      if (mediaStream) {
        mediaStream.getTracks().forEach(track => track.stop());
        mediaStream = null;
      }
      if (audioElement) {
        audioElement.srcObject = null;
        audioElement = null;
      }
      
      isConnected = false;
      isMuted = false;
      connectBtn.textContent = 'Connect';
      connectBtn.classList.remove('connected', 'listening');
      connectBtn.disabled = false;
      muteBtn.classList.remove('visible', 'muted');
      muteBtn.textContent = 'üé§';
      screenControls.classList.remove('visible');
      stopScreenShare();
      setStatus('Disconnected');
    }
    
    function toggleMute() {
      if (!mediaStream) return;
      
      isMuted = !isMuted;
      mediaStream.getAudioTracks().forEach(track => {
        track.enabled = !isMuted;
      });
      
      muteBtn.textContent = isMuted ? 'üîá' : 'üé§';
      muteBtn.classList.toggle('muted', isMuted);
      muteBtn.title = isMuted ? 'Unmute' : 'Mute';
    }
    
    async function shareScreen() {
      if (isScreenSharing) {
        stopScreenShare();
        return;
      }
      
      try {
        screenStream = await navigator.mediaDevices.getDisplayMedia({
          video: { cursor: 'always' },
          audio: false
        });
        
        screenPreview.srcObject = screenStream;
        screenPreview.classList.add('visible');
        shareScreenBtn.textContent = 'üñ•Ô∏è Stop Sharing';
        shareScreenBtn.classList.add('active');
        screenshotBtn.style.display = 'inline-block';
        ambientBtn.style.display = 'inline-block';
        isScreenSharing = true;
        
        // Handle when user stops sharing via browser UI
        screenStream.getVideoTracks()[0].onended = () => {
          stopScreenShare();
        };
        
        addTranscript('Screen sharing started. Say "take a screenshot" or click üì∏', 'assistant');
        
      } catch (err) {
        console.error('Screen share error:', err);
        setStatus('Screen share cancelled or failed', true);
      }
    }
    
    function stopScreenShare() {
      stopAmbientMode();
      if (screenStream) {
        screenStream.getTracks().forEach(track => track.stop());
        screenStream = null;
      }
      screenPreview.srcObject = null;
      screenPreview.classList.remove('visible');
      shareScreenBtn.textContent = 'üñ•Ô∏è Share Screen';
      shareScreenBtn.classList.remove('active');
      screenshotBtn.style.display = 'none';
      ambientBtn.style.display = 'none';
      isScreenSharing = false;
      lastScreenCapture = null;
    }
    
    function toggleAmbientMode() {
      if (isAmbientMode) {
        stopAmbientMode();
      } else {
        startAmbientMode();
      }
    }
    
    function startAmbientMode() {
      isAmbientMode = true;
      ambientBtn.classList.add('active');
      ambientBtn.textContent = 'üëÅÔ∏è Watching...';
      addTranscript('Ambient mode ON - I\'ll watch your screen. Minimize me and ask "what do you see" anytime!', 'assistant');
      
      // Capture immediately
      captureScreenSilent();
      
      // Then every 30 seconds
      ambientInterval = setInterval(() => {
        captureScreenSilent();
      }, 30000);
    }
    
    function stopAmbientMode() {
      if (ambientInterval) {
        clearInterval(ambientInterval);
        ambientInterval = null;
      }
      isAmbientMode = false;
      ambientBtn.classList.remove('active');
      ambientBtn.textContent = 'üëÅÔ∏è Ambient';
    }
    
    // Silent capture - just stores the image, doesn't analyze
    function captureScreenSilent() {
      if (!screenStream) return;
      
      const video = screenPreview;
      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      const ctx = canvas.getContext('2d');
      ctx.drawImage(video, 0, 0);
      
      lastScreenCapture = canvas.toDataURL('image/jpeg', 0.8);
      console.log('[Ambient] Screen captured silently');
    }
    
    async function takeScreenshot() {
      if (!screenStream && !lastScreenCapture) {
        setStatus('No screen being shared', true);
        return;
      }
      
      setStatus('üì∏ Capturing screenshot...');
      
      let imageData;
      
      if (screenStream) {
        // Fresh capture
        const video = screenPreview;
        const canvas = document.createElement('canvas');
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        const ctx = canvas.getContext('2d');
        ctx.drawImage(video, 0, 0);
        imageData = canvas.toDataURL('image/jpeg', 0.8);
        lastScreenCapture = imageData;
      } else if (lastScreenCapture) {
        // Use last ambient capture
        imageData = lastScreenCapture;
      }
      
      setStatus('üîç Analyzing screenshot...');
      addTranscript('Analyzing what I see...', 'assistant');
      
      try {
        const res = await fetch('https://genuine-palestinian-beautifully-areas.trycloudflare.com/api/screenshot', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ image: imageData, model: modelSelect.value })
        });
        
        const { analysis } = await res.json();
        
        addTranscript(analysis, 'assistant');
        
        // Speak the analysis if connected
        if (isConnected && dataChannel && dataChannel.readyState === 'open') {
          sendEvent({
            type: 'response.create',
            response: {
              instructions: `Say exactly the following, speaking naturally: "${analysis}"`,
              input: [{
                type: 'message',
                role: 'user',
                content: [{ type: 'input_text', text: `Please say: ${analysis}` }]
              }]
            }
          });
          setStatus('üîä Describing what I see...');
        } else {
          setStatus('Screenshot analyzed');
        }
        
      } catch (err) {
        console.error('Screenshot analysis error:', err);
        setStatus('Failed to analyze screenshot', true);
      }
    }
    
    // Mobile camera capture
    async function openCamera() {
      if (isScreenSharing) {
        stopScreenShare();
        return;
      }
      
      try {
        // Try to get camera stream for live preview
        screenStream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: 'environment' }, // Back camera
          audio: false
        });
        
        screenPreview.srcObject = screenStream;
        screenPreview.classList.add('visible');
        cameraBtn.textContent = 'üì∑ Stop Camera';
        cameraBtn.classList.add('active');
        screenshotBtn.style.display = 'inline-block';
        screenshotBtn.textContent = 'üì∏ Take Photo';
        ambientBtn.style.display = 'inline-block';
        isScreenSharing = true;
        
        screenStream.getVideoTracks()[0].onended = () => stopScreenShare();
        
        addTranscript('Camera active. Say "take a photo" or tap üì∏', 'assistant');
        
      } catch (err) {
        // Fallback to file picker if camera access denied
        console.log('Camera access denied, falling back to file picker');
        imageUpload.click();
      }
    }
    
    // Handle file upload (fallback for camera)
    imageUpload.onchange = async (e) => {
      const file = e.target.files[0];
      if (!file) return;
      
      const reader = new FileReader();
      reader.onload = async (event) => {
        lastScreenCapture = event.target.result;
        setStatus('üì∏ Analyzing image...');
        addTranscript('Analyzing your image...', 'assistant');
        
        try {
          const res = await fetch('https://genuine-palestinian-beautifully-areas.trycloudflare.com/api/screenshot', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ image: lastScreenCapture, model: modelSelect.value })
          });
          
          const { analysis } = await res.json();
          addTranscript(analysis, 'assistant');
          
          if (isConnected && dataChannel?.readyState === 'open') {
            sendEvent({
              type: 'response.create',
              response: {
                instructions: `Say exactly: "${analysis}"`,
                input: [{ type: 'message', role: 'user', content: [{ type: 'input_text', text: analysis }] }]
              }
            });
            setStatus('üîä Describing...');
          } else {
            setStatus('Image analyzed');
          }
        } catch (err) {
          setStatus('Failed to analyze image', true);
        }
      };
      reader.readAsDataURL(file);
      imageUpload.value = ''; // Reset for next use
    };
    
    connectBtn.onclick = connect;
    muteBtn.onclick = toggleMute;
    shareScreenBtn.onclick = shareScreen;
    cameraBtn.onclick = openCamera;
    screenshotBtn.onclick = takeScreenshot;
    ambientBtn.onclick = toggleAmbientMode;
    window.onbeforeunload = () => { disconnect(); stopScreenShare(); };
  </script>
</body>
</html>
<!-- Cache bust: 1769917958 -->
